version: "3.9"

networks:
  lakehouse-network:
    name: lakehouse-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 10.1.1.0/24
          gateway: 10.1.1.1

services:
  minio:
    image: bitnami/minio:2024
    container_name: minio
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.2
    hostname: minio
    environment:
      MINIO_ROOT_USER: username
      MINIO_ROOT_PASSWORD: password

  minio-client:
    image: bitnami/minio-client:2024
    container_name: minio-client
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.3
    hostname: minio-client
    environment:
      MINIO_SERVER_ACCESS_KEY: username
      MINIO_SERVER_SECRET_KEY: password
    command: >
      /bin/bash -c "
        until (mc alias set minio http://minio:9000 username password) do echo '...waiting...' && sleep 1; done;
        mc mb minio/lakehouse/bronze minio/lakehouse/silver minio/lakehouse/gold;
        mc anonymous set public minio/lakehouse;
        tail -f /dev/null
      "
    depends_on: [ minio ]

  starrocks-fe:
    image: starrocks/fe-ubuntu:3.2.4
    container_name: starrocks-fe
    user: root
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.4
    hostname: starrocks-fe
    environment:
      AWS_ACCESS_KEY_ID: username
      AWS_SECRET_ACCESS_KEY: password
    command: >
      /bin/bash -c "
        /opt/starrocks/fe/bin/start_fe.sh
      "
    depends_on: [ minio ]
    healthcheck:
      test: 'mysql -u root -h starrocks-fe -P 9030 -e "SHOW FRONTENDS\G" |grep "Alive: true"'
      interval: 10s
      timeout: 5s
      retries: 3

  starrocks-be:
    image: starrocks/be-ubuntu:3.2.4
    container_name: starrocks-be
    user: root
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.5
    hostname: starrocks-be
    environment:
      AWS_ACCESS_KEY_ID: username
      AWS_SECRET_ACCESS_KEY: password
    command: >
      /bin/bash -c "
        ulimit -u 65535;
        ulimit -n 65535;
        echo '# Enable data cache'  >> /opt/starrocks/be/conf/be.conf;
        echo 'block_cache_enable = true'  >> /opt/starrocks/be/conf/be.conf;
        echo 'block_cache_mem_size = 536870912' >> /opt/starrocks/be/conf/be.conf;
        echo 'block_cache_disk_size = 1073741824' >> /opt/starrocks/be/conf/be.conf;
        sleep 15s;
        mysql --connect-timeout 2 -h starrocks-fe -P 9030 -u root -e 'ALTER SYSTEM ADD BACKEND \"starrocks-be:9050\";';
        /opt/starrocks/be/bin/start_be.sh
      "
    depends_on: [ minio, starrocks-fe ]
    healthcheck:
      test: 'mysql -u root -h starrocks-fe -P 9030 -e "SHOW BACKENDS\G" |grep "Alive: true"'
      interval: 10s
      timeout: 5s
      retries: 3

  postgresql:
    image: bitnami/postgresql:16.2.0
    container_name: postgresql
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.6
    hostname: postgresql
    environment:
      POSTGRESQL_USERNAME: username
      POSTGRESQL_PASSWORD: password
    volumes:
      - ./config/postgresql/initdb/:/docker-entrypoint-initdb.d/

  metastore:
    image: starburstdata/hive:3.1.3-e.9
    container_name: metastore
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.7
    hostname: hive-metastore
    environment:
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://postgresql:5432/metastore
      HIVE_METASTORE_USER: username
      HIVE_METASTORE_PASSWORD: password
      HIVE_METASTORE_WAREHOUSE_DIR: s3a://lakehouse/silver-layer
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: username
      S3_SECRET_KEY: password
      S3_PATH_STYLE_ACCESS: "true"
      REGION: ""
      GOOGLE_CLOUD_KEY_FILE_PATH: ""
      AZURE_ADL_CLIENT_ID: ""
      AZURE_ADL_CREDENTIAL: ""
      AZURE_ADL_REFRESH_URL: ""
      AZURE_ABFS_STORAGE_ACCOUNT: ""
      AZURE_ABFS_ACCESS_KEY: ""
      AZURE_WASB_STORAGE_ACCOUNT: ""
      AZURE_ABFS_OAUTH: ""
      AZURE_ABFS_OAUTH_TOKEN_PROVIDER: ""
      AZURE_ABFS_OAUTH_CLIENT_ID: ""
      AZURE_ABFS_OAUTH_SECRET: ""
      AZURE_ABFS_OAUTH_ENDPOINT: ""
      AZURE_WASB_ACCESS_KEY: ""
      HIVE_METASTORE_USERS_IN_ADMIN_ROLE: admin
    depends_on: [ minio, postgresql ]

  mysql:
    image: bitnami/mysql:8.3.0
    container_name: mysql
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.8
    hostname: mysql
    environment:
      MYSQL_ROOT_USER: username
      MYSQL_ROOT_PASSWORD: password
      MYSQL_EXTRA_FLAGS: >
        --gtid-mode=ON
        --enforce_gtid_consistency=ON
    volumes:
      - ./config/mysql/initdb/:/docker-entrypoint-initdb.d/

  kafka:
    image: debezium/kafka:2.5.3.Final
    container_name: kafka
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.9
    hostname: kafka
    environment:
      CLUSTER_ID: 5Yr1SIgYQz-b-dgRabWx4g
      BROKER_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.0
    restart: on-failure
    container_name: schema-registry
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.10
    hostname: schema-registry
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: NONE
    depends_on: [ kafka ]

  debezium:
    image: debezium/cp-connect:2.5.3.Final
    build:
      context: ./images/debezium/2.5
    container_name: debezium
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.11
    hostname: debezium
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: _debezium.configs
      OFFSET_STORAGE_TOPIC: _debezium.offsets
      STATUS_STORAGE_TOPIC: _debezium.statuses
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    depends_on: [ kafka, schema-registry ]

  conduktor-platform:
    image: conduktor/conduktor-platform:1.21.1
    container_name: conduktor-platform
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.12
    hostname: conduktor-platform
    volumes:
      - type: bind
        source: "./config/conduktor/platform-config.yml"
        target: /opt/conduktor/platform-config.yml
        read_only: true
    environment:
      CDK_IN_CONF_FILE: /opt/conduktor/platform-config.yml
    depends_on: [ postgresql, kafka, schema-registry, debezium ]

  conduktor-monitoring:
    image: conduktor/conduktor-platform-cortex:1.21.1
    container_name: conduktor-monitoring
    restart: on-failure
    networks:
      lakehouse-network:
        ipv4_address: 10.1.1.13
    hostname: conduktor-monitoring
    environment:
      CDK_CONSOLE-URL: http://conduktor-platform:8080
    depends_on: [ conduktor-platform, postgresql ]


#  lakefs:
#    image: treeverse/lakefs:1.14.1
#    container_name: lakefs
#    restart: on-failure
#    networks:
#      lakehouse-network:
#        ipv4_address: 10.1.1.14
#    environment:
#      LAKEFS_DATABASE_TYPE: postgres
#      LAKEFS_DATABASE_POSTGRES_CONNECTION_STRING: postgres://username:password@postgresql:5432/lakefs
#      LAKEFS_AUTH_ENCRYPT_SECRET_KEY: password
#      LAKEFS_BLOCKSTORE_TYPE: s3
#      LAKEFS_BLOCKSTORE_S3_FORCE_PATH_STYLE: "true"
#      LAKEFS_BLOCKSTORE_S3_ENDPOINT: http://minio:9000
#      LAKEFS_BLOCKSTORE_S3_DISCOVER_BUCKET_REGION: "false"
#      LAKEFS_BLOCKSTORE_S3_CREDENTIALS_ACCESS_KEY_ID: username
#      LAKEFS_BLOCKSTORE_S3_CREDENTIALS_SECRET_ACCESS_KEY: password
#    command: [ "run" ]
#    depends_on: [ postgresql, minio ]
